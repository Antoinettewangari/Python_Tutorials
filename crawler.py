import requestsfrom bs4 import BeautifulSoup# requests is a module for connecting to the internet.# Beautiful soup allows us to loop through the contents to get exactly the results we want.def crawl_pages(max_pages):	page = 1	while page < max_pages:		url = '' + str(page)		# Connect to the webpage using its url & get everything from the webpage.		source_code = requests.get(url)		# Filter out the good stuff of the webpage: Links, images, e.t.c		plain_txt = source_code.text		# Create a Beautiful soup object to help in looping through the webpage's content		soup = BeautifulSoup(plain_txt)		for link in soup.findAll('a', {'rel': 'bookmark'}):			# Get the links.			href = link.get('href')			# Get the Link title			title = link.string			print(href)			print(title)			# get_single_data(href)		page += 1'''def get_single_data(item_url):	source_code = requests.get(item_url)	plain_txt = source_code.text	soup = BeautifulSoup(plain_txt)	for item in soup.findAll('div', {'class': 'i-name'}):		print(item.string)		'''crawl_pages(3)